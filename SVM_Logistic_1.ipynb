{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aae3a8e",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b895fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b319a68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Parkinson-Disease\n",
      "F:\\Parkinson-Disease\\Data set\\Parkinson disease.csv\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "print(os.getcwd())\n",
    "data_dir = os.getcwd() + \"\\\\Data set\\\\Parkinson disease.csv\"\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9189c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195 entries, 0 to 194\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              195 non-null    object \n",
      " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
      " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
      " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
      " 4   MDVP:Jitter(%)    195 non-null    float64\n",
      " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
      " 6   MDVP:RAP          195 non-null    float64\n",
      " 7   MDVP:PPQ          195 non-null    float64\n",
      " 8   Jitter:DDP        195 non-null    float64\n",
      " 9   MDVP:Shimmer      195 non-null    float64\n",
      " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
      " 11  Shimmer:APQ3      195 non-null    float64\n",
      " 12  Shimmer:APQ5      195 non-null    float64\n",
      " 13  MDVP:APQ          195 non-null    float64\n",
      " 14  Shimmer:DDA       195 non-null    float64\n",
      " 15  NHR               195 non-null    float64\n",
      " 16  HNR               195 non-null    float64\n",
      " 17  status            195 non-null    int64  \n",
      " 18  RPDE              195 non-null    float64\n",
      " 19  DFA               195 non-null    float64\n",
      " 20  spread1           195 non-null    float64\n",
      " 21  spread2           195 non-null    float64\n",
      " 22  D2                195 non-null    float64\n",
      " 23  PPE               195 non-null    float64\n",
      "dtypes: float64(22), int64(1), object(1)\n",
      "memory usage: 36.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['name', 'MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
       "       'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP',\n",
       "       'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5',\n",
       "       'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'status', 'RPDE', 'DFA',\n",
       "       'spread1', 'spread2', 'D2', 'PPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parkinson = pd.read_csv(data_dir, delimiter = \",\")\n",
    "df_parkinson.info()\n",
    "df_parkinson.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4424911d",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a0bbcf",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94343074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195, 22) (195,)\n"
     ]
    }
   ],
   "source": [
    "X=(df_parkinson.iloc[:,1:]).drop(columns=[\"status\"])\n",
    "y = df_parkinson.status\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "054b7336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d41694",
   "metadata": {},
   "source": [
    "# Training model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d990c3c",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2138cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c8c6c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score : 89.83%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LoR_model = LogisticRegression(solver= 'liblinear')\n",
    "LoR_model.fit(X_train, y_train)\n",
    "y_pred_test = LoR_model.predict(X_test)\n",
    "y_pred_train = LoR_model.predict(X_train)\n",
    "\n",
    "gt_array = [y_train, y_test] # ground truth\n",
    "pred_array = [y_pred_train, y_pred_test] # predictions\n",
    "print('Model accuracy score : {:0.2%}'. format(accuracy_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d684326",
   "metadata": {},
   "source": [
    "### k fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d418282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1, Train set: 156, Test set:39\n",
      "Fold:2, Train set: 156, Test set:39\n",
      "Fold:3, Train set: 156, Test set:39\n",
      "Fold:4, Train set: 156, Test set:39\n",
      "Fold:5, Train set: 156, Test set:39\n",
      "Scores for each fold are: [87.18 82.05 89.74 84.62 82.05]\n",
      "Average score: 85.13 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "kf =KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cnt = 1\n",
    "# split()  method generate indices to split data into training and test set.\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print(f'Fold:{cnt}, Train set: {len(train_index)}, Test set:{len(test_index)}')\n",
    "    cnt += 1\n",
    "score1 = cross_val_score(LogisticRegression(solver= 'liblinear') , X, y, cv= kf, scoring=\"accuracy\")\n",
    "print(f'Scores for each fold are: {score1.round(4)*100}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score1.mean()*100)}',\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b8836",
   "metadata": {},
   "source": [
    "### Standard scaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bbf3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=(df_parkinson.iloc[:,1:]).drop(columns=[\"status\"])\n",
    "y = df_parkinson.status\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47fd3f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.864406779661017\n"
     ]
    }
   ],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the decision tree model\n",
    "svm_model = LogisticRegression(solver= 'liblinear')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = svm_model.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce6833c",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a4a3334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score : 67.80%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the random forest classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB_model = GaussianNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "y_pred_test = NB_model.predict(X_test)\n",
    "y_pred_train = NB_model.predict(X_train)\n",
    "\n",
    "gt_array = [y_train, y_test] # ground truth\n",
    "pred_array = [y_pred_train, y_pred_test] # predictions\n",
    "print('Model accuracy score : {:0.2%}'. format(accuracy_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d23a548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1, Train set: 156, Test set:39\n",
      "Fold:2, Train set: 156, Test set:39\n",
      "Fold:3, Train set: 156, Test set:39\n",
      "Fold:4, Train set: 156, Test set:39\n",
      "Fold:5, Train set: 156, Test set:39\n",
      "Scores for each fold are: [69.23 74.36 71.79 64.1  69.23]\n",
      "Average score: 69.74 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "kf =KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cnt = 1\n",
    "# split()  method generate indices to split data into training and test set.\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print(f'Fold:{cnt}, Train set: {len(train_index)}, Test set:{len(test_index)}')\n",
    "    cnt += 1\n",
    "score1 = cross_val_score(GaussianNB() , X, y, cv= kf, scoring=\"accuracy\")\n",
    "print(f'Scores for each fold are: {score1.round(4)*100}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score1.mean()*100)}',\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e0c44bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.79661016949152\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the decision tree model\n",
    "NB_model = GaussianNB()\n",
    "NB_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = NB_model.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2726177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
